{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulación de datos\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Gráficos\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import hvplot.pandas\n",
    "\n",
    "\n",
    "# Preprocesamiento y modelado\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos los datos necesarios\n",
    "\n",
    "ruta_archivo = Path(\"../###/###.csv\")\n",
    "\n",
    "data_archivo = pd.read_csv(ruta_archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación de datos categóricos a numéricos para una columna categórica\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "columna_categorica_numerica = label_encoder.fit_transform(data_archivo[\"columna_categorica\"])\n",
    "data_archivo[\"columna_categorica\"] = columna_categorica_numerica\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Transformación de datos categóricos a numéricos para varias columnas categóricas\n",
    "\n",
    "labelencoder_categoricas = {}\n",
    "for columna in data_archivo.columns:\n",
    "    if data_archivo[columna].dtype == \"object\":\n",
    "        labelencoder_categoricas[columna] = LabelEncoder()\n",
    "        data_archivo[columna] = labelencoder_categoricas[columna].fit_transform(obesidad_datos[columna].astype(str))\n",
    "\n",
    "data_archivo.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos si faltan valores en el dataframe mediante distintas funciones\n",
    "\n",
    "data_archivo.info()\n",
    "\n",
    "data_archivo.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas / columnas con valores faltantes\n",
    "\n",
    "data_archivo.dropna(axis=0, inplace=True) # Columnas\n",
    "\n",
    "data_archivo.dropna(axis=1, inplace=True) # Filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputación de los datos\n",
    "\n",
    "#Creamos y aplicamos el KNNImputer\n",
    "imputador_knn = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Realizar la imputación\n",
    "datos_imputados = pd.DataFrame(imputador_knn.fit_transform(data_archivo), columns=data_archivo.columns)\n",
    "\n",
    "\n",
    "datos_imputados.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos de nuevo los valores NaN\n",
    "\n",
    "total_nan = datos_imputados.isna().sum().sum()\n",
    "\n",
    "print(f\"Número total de valores nulos: {total_nan}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarización de los datos\n",
    "scaler = StandardScaler() # Crea una instancia de StandardScaler\n",
    "\n",
    "# Estandariza los datos utilizando la instancia de StandarScaler\n",
    "data_standardized = scaler.fit_transform(datos_imputados)\n",
    "\n",
    "# Muestra los datos estandarizados\n",
    "data_standardized[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la semilla aleatoria\n",
    "\n",
    "random_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero comprobaremos los distintos componentes del PCA para luego elegir\n",
    "\n",
    "pca = PCA()\n",
    "datos.pca = pca.fit_transform(datos_imputados)\n",
    "\n",
    "# Creamos una visualización de estos componentes principales\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "x = range(1, len(pca.explained_variance_ratio_)+1)\n",
    "y = pca.explained_variance_ratio.cumsum()\n",
    "plt.plot(x, y, marker='o', linestyle='--')\n",
    "plt.title('Varianza explicada por los componentes')\n",
    "plt.xlabel('Número de componentes')\n",
    "plt.ylabel('Varianza explicada acumulada')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UNIRBien",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
